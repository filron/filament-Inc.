# Data Analysis / Data Science / Mahine Learning / Deep Learning

## Modules/Libs
1. Numpy
2. Pandas
3. Matplotlib
4. Seaborn
5. Scikit-Learn
6. Plotly



* pip
* dlib
* cmake
* opencv-python
* imutils
* itertools
* scipy
* merkletools
* tensorflow
* keras
* pytorch
* gluoncv
* mxnet


## Opencv
```python
import cv2
cv2.videoCapture(0).read()
cv2.destroyAllWindows()
```
## Matplotlib

```python
import numpy as np
import matplotlib.pyplot as plt

a=[0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180]
b=[180, 195, 210, 225, 240, 255, 270, 285, 300, 315, 330, 345, 360]

#plot 1
plt.plot(np.sin(a+b), label='sin(a+b)')
plt.plot()
```
## Numpy

```python
import numpy as np
np.mean()
np.median()
np.std()
np.percentile()
np.cbrt()
```

## Bayesian Mathemathics (Statistics)

bayes theorem (probablistic theorem)
conditional probablity
observed probablity
likelihood

monte carlo methods based on bayesian methods

hypothesis
false positive
true positives
false negetives
true negetives


## Regression Analysis
  * Simple Linear Regression
  * Multi Linear Regression
  * polynomial Regression
  * Logistic Regression
  * ridge Regression
  * Lasso Regression


## Toy Dataset

iris dataset
fashion mnist dataset
titanic dataset
pixar_movies dataset
cancer dataset


## Type of Plots
plot
scatter plot (2D and 3D)
box plot (whisker plot)
pair plot
quiver plot
histogram:
	used to plot density of variable
violin plot
joint plot
swarm plot
heat map / plot
polar plot
stream line plot
barb plot
polar scatter plot


## Mathemathics for Machine Learning

1. Linear Algebra
	* PCA (principal component analysis)
	* SVD (single value decomposition)
	* Eigen decomposition of a matrix
	* LU decomposition
	* QR decomposition
	* Symmetric matrices
	* orthogonalization and orthonormalization of matrix
	* matrix operations
	* projection
	* eigen vectors and eigen values
	* vector spaces and norms
	
2. Calculus
    * Multivariate calculus
	* basic differential and integral calculus
	* partial derivatives
	* vector value functions
	* directional gradient
	* hessian, jacobian, lagrange, laplacian distributions
	* optimization theory
	
3. Statistics and Probablity
    * probablity theory
	* combinatorics
	* probablity rules and axioms
	* bayes theorrem
	* random variables
	* variance and expectations
	* conditional and observed probablities
	* conditional and disjoint distributions
	* standard deviation
	* bernoullis, binomial, multinomial, uniform, gaussian probablity distribution
	* moment generating functions
	* MLE (maximum likelihood functions)
	* MAP (maximum aposteriori estimation)
	* priori and posterior
	* sampling methods
	
4. Algorithm and complex optimization
	* binary tree
	* hashing techniques
	* heap
	* stack
	* dynamic programming, divide and conquer, greedy algorithms
	* randomized and sublinear algorithms
	* graph, gradient, stochastic descents
	* primal dual methods
  
5. Reference
	
  * [towards data science (the mathemathics of machine learning) Wale Akinfaderin](https://towardsdatascience.com/the-mathematics-of-machine-learning-894f046c568)
	* 

## OTHERS
* mean and variance are corupted by outliers
* median is not corupted by outliers
* median can only be corupted if half the data points are outliers
* variance is squared difference
* 

## Questions
1. what is data point/observation?
2. what are outliers and how to fix them?
1. when to use histogram?, box ans whiskers?, pair plot, 
2. what is EDA (Exploratory data analysis)?
3. how to visualize multi dimentional data?
4. how to visualize 2 dimentional data?
5. what is IQR (Inter Quartile Range)?
6. what is PDF (Probablity Density Function) and PMF (Probablity Mass Function)?
7. how to visualize univariate and multi variate data?
8. 

///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
//
///////////////////////////////////////////////////////////////////////////////
